IMMEDIATE
--------------------------------------------------------------------------------------------------------------------------------------------

-understanding deep learning:
mess around with pytorch/tensorflow
simple experiments in controlled environments => simple theroms => insight
any model that works on complex domain should work well for the linear case (understand linear+ have intuition)
model validation(can't CV): noah dolev-subsample your test set (each class with prob p), add noise to each feature (independent/correlated) using learning variance from train, calculate loss of test subsamples and repeat with bootstrap 

-deep learning for text (autoencoders? recurrent LSTM? something something)
-also word2vec as baseline can be cute (summerization, autoreply, better hmm text generator, translate,...)
-seq2seq with attention?

PID? it looks interesting, RHC seems like a cool expand

GREAT STUFF
---------------------------------------------------------------------------------------------------------------------------------------------

-Generative Advarserial Networks
as unsupervised learning (mostly in RL)
adam performs well - accidental? adam overfits and exagerates existing features
aiden.nibali.org/blog/
human originality as irrationality or ignoring probabilty distribution in a trained model? sometimes? 
energy based GANs

general reinforcment learning: (not just GANS- meh?)
-General intelligence as maximizing future options? interesting concept(maybe use as way to tag samples-increase future options good and decrease bad on 1:2 ratio)
->maybe add deep learning(learn deep concept/good representation from simple representation(i.e. pixels)->good with sensors. can also work with unlabled data)
->what the heck does "future options" even mean in most contexts we use? Is this generalizable? relation to simple biological functions?
-agent competition
-agent imitation
-NN noise in reinforcement learning (combine with something)
-imagination? (deepbrain) dreams? compress world -> train RNN to predict the probability of the compression space(MDN-RNN to predict future prob)
-RL as a control problem (ILC (iterative learning control) control problems assume strong physics model, but learn well with few examples, RL assumes very little and needs a ton of examples. middle ground?)
corollary is genetic algs are kinda meh
beware "adaptive" methods, usually not better than random search and they tend to exagerate/overfit like adam
deepmind (unsuperviesed auxiliary tasks/imagination/deep reinforcment learning/differentiable neural computers/continual learning)
openAI evolution strategies(evolution hill climb) better than policy gradient (how about random search)
can we do something with papers on bandits?
-model for setting reward (every K steps) + model free to move to it. Also EM where E is setting world distribution and M is best policy given that distribution

hyperparameter tuning: bayesian methods (fast converge but take long to compute. plays well with good initialization/early stopping/cutoff) 
					v random search (still a good option) 
					v halving random search (run K versions for time T/K, then kill half - the bad ones and double K. T=examples/epochs, K=params configs) see hyperband
using "simplicity" (depth, neurons, weights) for regularization? genetic alg -> random guided search -> maybe some strong gurentee?
can we do something with papers on bandits?
autoML is very enticing! but alchemy?

varmodel/lstm for time series data/anomaly detect

exloration/exploitation for model/reward shaping in RL(like EM, next level)

MAYBE
--------------------------------------------------------------------------------------------------------------------------------------------

"large margin" for deep learning?

openai requests for research is neat

MEH
------------------------------------------------------------------------------------------------------------------------------------
-deep learning without parameters? something better than genetic alg? -> this can't really work any better than random search...

-extending my work:
-using graphical models after the first step as recursive classifier (converting non-graphical problems to graphical ones! now you have a label propagation problem. can mby solve like pagerank algorithm?)
->can mby use tfidf as weights for labeling
-making the alg at least a bit more scalable (horrible complexity is horrible)
-idea (credit to omer levy): is there a way to generalize the relations used? (the classifier uses very specific relations, but it's possible that a very similar relation exist that can be used as well. could mby do this using schema tricks?)

Minor stuff:
-ideas models better than deterministic ones since can offer confidence->can rank positive results by confidence(like in watson), especially in relational case? see also topic models for recommendation/data mining
- crypto lens for learning (zero knowledge, private learning, learning over functional encryption)
-smart parameter tuning on anytime algorithms(mby use statistical tests to help with time)
